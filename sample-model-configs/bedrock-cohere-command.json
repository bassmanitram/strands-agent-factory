{
  "temperature": 0.6,
  "max_tokens": 2048,
  "top_p": 0.8,
  "top_k": 50,
  "stop_sequences": ["--"],
  "return_likelihoods": "GENERATION",
  "truncate": "NONE",
  "num_generations": 1
}